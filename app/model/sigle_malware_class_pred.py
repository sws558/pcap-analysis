import numpy as np
import pandas as pd
import tensorflow as tf
from keras.models import Model
from app.extract_tls import preprocess_pcap
from sklearn.metrics import classification_report
from keras.layers import Input, Lambda, Conv1D, MaxPooling1D, TimeDistributed, Bidirectional, Dense, GRU
from .AttentionNetwork import HierarchicalAttentionNetwork
from app import app
PACKET_NUM_PER_SESSION = 30
PACKET_LEN = 300
BATCH_SIZE = 32  #没用到？
LSTM_UNITS = 92  #没用到？

def read_batch(data_raw):
    # data_raw = np_data["data"]  # 多分类
    # data_raw = data_raw.tolist()

    data_arr = []
    for i in range(len(data_raw)):
        data_arr.append(data_raw[i]["data"])

    if len(data_arr) == 0:
        print("read_batch none")
        return None

    pcapdata = np.array(data_arr)
    # print(pcapdata)
    pcapdata = pcapdata[:, :PACKET_NUM_PER_SESSION, :PACKET_LEN] * 255

    pcapdata_reshape = pcapdata.reshape((-1, PACKET_NUM_PER_SESSION, PACKET_LEN))

    return pcapdata_reshape

def binarize(x, sz=256):
    return tf.cast(tf.one_hot(x, sz, on_value=1, off_value=0, axis=-1),dtype=tf.float32)

def binarize_outshape(in_shape):
    return in_shape[0], in_shape[1], 256

def byte_block(in_layer, nb_filter=(64, 100), filter_length=(3, 3), subsample=(2, 1), pool_length=(2,2)):
    #输入，滤波器数量，卷积核长度，池化大小，conv1d
    block = in_layer
    for i in range(len(nb_filter)):
        block = Conv1D(filters=nb_filter[i],
                       kernel_size=filter_length[i],
                       padding='valid',
                       activation='tanh',
                       strides=subsample[i])(block)
        if pool_length[i]:
            block = MaxPooling1D(pool_size=pool_length[i])(block)

    return block

def makeModel():#16分类？
    session = Input(shape=(PACKET_NUM_PER_SESSION, PACKET_LEN), dtype='int64')
    input_packet = Input(shape=(PACKET_LEN,), dtype='int64')
    embedded = Lambda(binarize, output_shape=binarize_outshape)(input_packet)
    block = byte_block(embedded, (192, 320), filter_length=(6, 5), subsample=(1, 1), pool_length=(2,2))
    attn_package = HierarchicalAttentionNetwork(192)(block)
    encoder = Model(inputs=input_packet, outputs=attn_package)
    encoder.summary()

    review_encoder = TimeDistributed(encoder)(session)
    gru_flow = Bidirectional(GRU(512, return_sequences=True,dropout = 0.1,recurrent_dropout=0.1))(review_encoder)
    attn_flow = HierarchicalAttentionNetwork(512)(gru_flow)
    preds = Dense(16, activation='softmax')(attn_flow)
    model = Model(outputs=preds, inputs=session)
    model.summary()
    return model

def predict(weight_path, pcap_filepath):
    #使用训练好的模型对新的输入数据进行分类预测。
    model = makeModel()
    print("read model")
    model.load_weights(weight_path)
    # model.compile(loss="categorical_crossentropy", optimizer='rmsprop', metrics=['accuracy'])
    mode = []
    mode = app.config["MODE_5"]
    model.compile(loss=mode[0],
                  optimizer=tf.optimizers.RMSprop(learning_rate=mode[1]), 
                  metrics=mode[2],
                  steps_per_execution = mode[3])
    # model.compile(loss="Weighted Crossentropy", optimizer='Adam', metrics=['accuracy'])
    np_data, csv_filepath = preprocess_pcap(pcap_filepath)
    X = read_batch(np_data)
    if X is None:
        print("predict none")

        return pd.DataFrame([])
    print("start predict")
    predictions = model.predict(X)
    predicted_labels = np.argmax(predictions, axis=1)
    predicted_labels = predicted_labels.astype(np.int64)
    print(predicted_labels)
    predicted_labels = predicted_labels.tolist()
    print(predicted_labels)
    target_names = ["Ewind","plankton","Nandrobox","Biige","VirusShield","FakeAV","AndroidSpy.277","WannaLocker","RansomBO","LockerPin","Charger","Youmi","Kemoge"]
    target_index = [0,1,2,4,5,6,8,9,10,11,12,14,15]
    target_label_map = dict(zip(target_index, target_names))
    predicted_labels = [target_label_map[i] for i in predicted_labels]

    df = pd.read_csv(csv_filepath)
    df["predicted_labels"] = predicted_labels

    return df

if __name__ == "__main__":
    print(predict("./app/model/save_model/_300_30_single_malware.hdf5", "store/pcap/vdnwhx9qlp.pcap"))